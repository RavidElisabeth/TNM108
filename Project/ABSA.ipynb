{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers[sentencepiece]\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import zipfile\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Documents\\GitHub\\TNM108\\Project\\venv\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Aspect-Based Sentiment Analysis model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification \\\n",
    "  .from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Load a traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path,\n",
    "                          tokenizer=sentiment_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for how the code works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: We had a great experience at the restaurant, food was delicious, but the service was kinda bad\n",
      "\n",
      "Sentiment of aspect 'food' is:\n",
      "Label negative: 0.000998911913484335\n",
      "Label neutral: 0.0018238150514662266\n",
      "Label positive: 0.997177243232727\n",
      "\n",
      "Sentiment of aspect 'service' is:\n",
      "Label negative: 0.9946129322052002\n",
      "Label neutral: 0.0023699868470430374\n",
      "Label positive: 0.003017081180587411\n",
      "\n",
      "Overall sentiment: negative with score 0.7706007361412048\n"
     ]
    }
   ],
   "source": [
    "sentence = \"We had a great experience at the restaurant, food was delicious, but \" \\\n",
    "  \"the service was kinda bad\"\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print()\n",
    "\n",
    "aspect = \"food\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"service\"\n",
    "aspect = \"service\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "# Sentiment of aspect 'service' is:\n",
    "# Label negative: 0.9946129322052002\n",
    "# Label neutral: 0.002369985682889819\n",
    "# Label positive: 0.003017079783603549\n",
    "\n",
    "# Overall sentiment of the sentence\n",
    "sentiment = sentiment_model([sentence])[0]\n",
    "print(f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "# Overall sentiment: Negative with score 0.7706006765365601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for analysing sentiment of different aspects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_aspects_sentiment(sentence, aspects, absa_tokenizer, absa_model):\n",
    "#     for aspect in aspects:\n",
    "#         # Tokenize the input\n",
    "#         inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "        \n",
    "#         # Get the model outputs\n",
    "#         outputs = absa_model(**inputs)\n",
    "        \n",
    "#         # Apply softmax to obtain probabilities\n",
    "#         probs = F.softmax(outputs.logits, dim=1)\n",
    "#         probs = probs.detach().numpy()[0]  # Convert tensor to numpy array\n",
    "        \n",
    "#         # Print the sentiment probabilities\n",
    "#         print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "#         for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "#             print(f\"  {label.capitalize()}: {prob:.4f}\")\n",
    "#         print()  # Add a newline for better readability\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def analyze_aspects_sentiment(sentence, aspects, absa_tokenizer, absa_model, sentiment_model):\n",
    "    sentiment_results = {}\n",
    "\n",
    "    # Analyze sentiment for each aspect (e.g., food, service)\n",
    "    for aspect in aspects:\n",
    "        if aspect.lower() not in sentence.lower():\n",
    "            print(f\"Aspect '{aspect}' not found in the sentence.\")\n",
    "            continue  # Skip sentiment analysis for this aspect\n",
    "        inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "        outputs = absa_model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "        probs = probs.detach().numpy()[0]\n",
    "        \n",
    "        # Format aspect sentiment result\n",
    "        sentiment_results[aspect] = {\n",
    "            \"negative\": probs[0],\n",
    "            \"neutral\": probs[1],\n",
    "            \"positive\": probs[2]\n",
    "        }\n",
    "\n",
    "        # Print the sentiment of the aspect in the requested format\n",
    "        print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "        for label, prob in sentiment_results[aspect].items():\n",
    "            print(f\"Label {label}: {prob}\")\n",
    "        print()\n",
    "\n",
    "    # Overall sentiment of the sentence\n",
    "    sentiment = sentiment_model([sentence])[0]\n",
    "    print(f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "\n",
    "    return sentiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 397629 entries, 162840 to 92778\n",
      "Data columns (total 34 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           397629 non-null  object \n",
      " 1   created_at                     397629 non-null  object \n",
      " 2   geo                            2564 non-null    object \n",
      " 3   lang                           397629 non-null  object \n",
      " 4   place                          30832 non-null   object \n",
      " 5   coordinates                    2564 non-null    object \n",
      " 6   user.favourites_count          397629 non-null  int64  \n",
      " 7   user.statuses_count            397629 non-null  int64  \n",
      " 8   user.description               353403 non-null  object \n",
      " 9   user.location                  302677 non-null  object \n",
      " 10  user.id                        397629 non-null  int64  \n",
      " 11  user.created_at                397629 non-null  object \n",
      " 12  user.verified                  397629 non-null  bool   \n",
      " 13  user.following                 397629 non-null  bool   \n",
      " 14  user.url                       172193 non-null  object \n",
      " 15  user.listed_count              397629 non-null  int64  \n",
      " 16  user.followers_count           397629 non-null  int64  \n",
      " 17  user.default_profile_image     397629 non-null  bool   \n",
      " 18  user.utc_offset                273213 non-null  float64\n",
      " 19  user.friends_count             397629 non-null  int64  \n",
      " 20  user.default_profile           397629 non-null  bool   \n",
      " 21  user.name                      397614 non-null  object \n",
      " 22  user.lang                      397629 non-null  object \n",
      " 23  user.screen_name               397629 non-null  object \n",
      " 24  user.geo_enabled               397629 non-null  bool   \n",
      " 25  user.profile_background_color  397629 non-null  object \n",
      " 26  user.profile_image_url         397629 non-null  object \n",
      " 27  user.time_zone                 273213 non-null  object \n",
      " 28  id                             397629 non-null  int64  \n",
      " 29  favorite_count                 397629 non-null  int64  \n",
      " 30  retweeted                      397629 non-null  bool   \n",
      " 31  source                         397629 non-null  object \n",
      " 32  favorited                      397629 non-null  bool   \n",
      " 33  retweet_count                  397629 non-null  int64  \n",
      "dtypes: bool(7), float64(1), int64(9), object(17)\n",
      "memory usage: 87.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'election_day_tweets_data/election_day_tweets.csv' \n",
    "elections_2016 = pd.read_csv(file_path)\n",
    "\n",
    "elections_2016.sort_values(by='created_at').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        #t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = re.sub(r\"#\", \"\", t)\n",
    "        t = re.sub(r\"#\", \"\", t)  # Remove only the '#' symbol\n",
    "        #t = 'http' if t.startswith('http') else t\n",
    "        #remove links (URLs)\n",
    "        t = re.sub(r'http\\S+|www\\S+|https\\S+', '', t)\n",
    "        new_text.append(t)\n",
    "        t = t.lower().strip()\n",
    "\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on some tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      .@lawrence @hillaryclinton two first  @senschumer tomorrow. @thelastword #brooklyn  therealamerica #vote #democrats #nastywomenvote #senate\n",
      "1    my @latimesopinion op-ed on historic #california #senate race. first time an elected woman senator succeeds another.\\nhttps://t.co/cbjqtk0q1v\n",
      "2                                        #senate wisconsin senate preview: johnson vs. feingold, the sequel https://t.co/xhq4p0v4el @senronjohnson\n",
      "3           if rubio wins and #trump loses in #florida... #hillaryclinton #senate #republicanprimary #senaterace #miami... https://t.co/zienecvnmo\n",
      "4                                #senate wisconsin senate preview: johnson vs. feingold, the sequel https://t.co/vsd6arfme5 senronjohnson nta•news\n",
      "Name: text, dtype: object\n",
      "                                                                                                                             cleaned_text\n",
      "0  .@lawrence @hillaryclinton two first  @senschumer tomorrow. @thelastword brooklyn  therealamerica vote democrats nastywomenvote senate\n",
      "1                    my @latimesopinion op-ed on historic california senate race. first time an elected woman senator succeeds another.\\n\n",
      "2                                                       senate wisconsin senate preview: johnson vs. feingold, the sequel  @senronjohnson\n",
      "3                                if rubio wins and trump loses in florida... hillaryclinton senate republicanprimary senaterace miami... \n",
      "4                                               senate wisconsin senate preview: johnson vs. feingold, the sequel  senronjohnson nta•news\n",
      "Example Hillary Tweets:\n",
      "                                                                                                                              cleaned_text\n",
      "26                                              even if hillary wins, nothing will change unless the democrats take back the senate. vote!\n",
      "46                     agree, the after effect may humble gop even more if @thedemocrats can take the senate . hillary has shown she can… \n",
      "57  politico says democrats are on the brink of taking back the senate! let's make it happen.! voteblue!! hillary senate house state local\n",
      "60                                                                       senate franken hits the road for clinton in minnesota  @alfranken\n",
      "62                                                               senate franken hits the road for clinton in minnesota  alfranken nta•news\n",
      "\n",
      "Example Trump Tweets:\n",
      "                                                                                                      cleaned_text\n",
      "3         if rubio wins and trump loses in florida... hillaryclinton senate republicanprimary senaterace miami... \n",
      "7                                      she's done america!! please vote for @realdonaldtrump maga for all of us!! \n",
      "22  its election day 2016 est. vote clintonkaine2016 senate democrats bluewave2016 forwardtogether lovetrumpshate \n",
      "59                                     senate sessions stumps for trump, rises on national stage  @senatorsessions\n",
      "61                             senate sessions stumps for trump, rises on national stage  senatorsessions nta•news\n"
     ]
    }
   ],
   "source": [
    "# Set pandas display options to show the full content of cells\n",
    "pd.set_option('display.max_colwidth', None)  # Show full text in columns\n",
    "pd.set_option('display.max_rows', None)  # Optional: Show all rows if needed\n",
    "\n",
    "elections_2016['text'] = elections_2016['text'].str.lower()  # Convert to lowercase\n",
    "print(elections_2016['text'].head())\n",
    "# Apply the cleaning function to the 'text' column\n",
    "elections_2016['cleaned_text'] = elections_2016['text'].apply(preprocess)\n",
    "print(elections_2016[['cleaned_text']].head())\n",
    "# Define specific words to search for\n",
    "specific_words = ['hillary', 'clinton']\n",
    "our_specific_words = ['hillary', 'clinton', 'trump']\n",
    "\n",
    "# Combine the words into a single regular expression pattern\n",
    "pattern = '|'.join(rf'\\b{word}\\b' for word in specific_words)  # Matches whole words only\n",
    "pattern2 = '|'.join(rf'\\b{word}\\b' for word in our_specific_words)  # Matches whole words only\n",
    "\n",
    "# Filter rows where the cleaned text contains any of the specific words\n",
    "trump_tweets = elections_2016[elections_2016['cleaned_text'].str.contains('trump', case=False, na=False)].copy()\n",
    "hillary_tweets = elections_2016[elections_2016['cleaned_text'].str.contains(pattern, flags=re.IGNORECASE, na=False)].copy()\n",
    "interesting_tweets = elections_2016[elections_2016['cleaned_text'].str.contains(pattern2, flags=re.IGNORECASE, na=False)].copy()\n",
    "# Save the filtered results\n",
    "#filtered_elections_2016.to_csv('filtered_words2.csv', index=False)\n",
    "\n",
    "# Display example Hillary Tweets\n",
    "print(\"Example Hillary Tweets:\")\n",
    "print(hillary_tweets[['cleaned_text']].head())  # Show the first 5 tweets related to Hillary\n",
    "\n",
    "# Display example Trump Tweets\n",
    "print(\"\\nExample Trump Tweets:\")\n",
    "print(trump_tweets[['cleaned_text']].head())  # Show the first 5 tweets related to Trump\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall tweets and sentiment\n",
      "Tweet: donald trump elected as 45th us president, defeating democrat nominee hillaryclinton , per us media\n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.02339293248951435\n",
      "Label neutral: 0.5201062560081482\n",
      "Label positive: 0.456500768661499\n",
      "\n",
      "Sentiment of aspect 'hillary' is:\n",
      "Label negative: 0.8718752264976501\n",
      "Label neutral: 0.12266005575656891\n",
      "Label positive: 0.0054647307842969894\n",
      "\n",
      "Sentiment of aspect 'clinton' is:\n",
      "Label negative: 0.864477813243866\n",
      "Label neutral: 0.12955081462860107\n",
      "Label positive: 0.0059714107774198055\n",
      "\n",
      "Overall sentiment: negative with score 0.5205474495887756\n",
      "\n",
      "Tweet: borthers and sisters, please get out and vote for hillary clinton imwithher2016 \n",
      "Aspect 'trump' not found in the sentence.\n",
      "Sentiment of aspect 'hillary' is:\n",
      "Label negative: 0.0034507703967392445\n",
      "Label neutral: 0.017090870067477226\n",
      "Label positive: 0.9794583320617676\n",
      "\n",
      "Sentiment of aspect 'clinton' is:\n",
      "Label negative: 0.005371887236833572\n",
      "Label neutral: 0.059505634009838104\n",
      "Label positive: 0.9351224899291992\n",
      "\n",
      "Overall sentiment: neutral with score 0.43160632252693176\n",
      "\n",
      "Tweet: good luck to my american friends and family election2016 trump clinton\n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.013303275220096111\n",
      "Label neutral: 0.979248046875\n",
      "Label positive: 0.0074486639350652695\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Sentiment of aspect 'clinton' is:\n",
      "Label negative: 0.019724881276488304\n",
      "Label neutral: 0.9752995371818542\n",
      "Label positive: 0.004975573625415564\n",
      "\n",
      "Overall sentiment: positive with score 0.7360132336616516\n",
      "\n",
      "Tweet: fuck trump election2016\n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.9962092638015747\n",
      "Label neutral: 0.002846754854544997\n",
      "Label positive: 0.000944010796956718\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Aspect 'clinton' not found in the sentence.\n",
      "Overall sentiment: negative with score 0.8820025324821472\n",
      "\n",
      "Tweet: election2016 go hillary clinton ! women rule, all the way to the white house !\n",
      "Aspect 'trump' not found in the sentence.\n",
      "Sentiment of aspect 'hillary' is:\n",
      "Label negative: 0.0062885163351893425\n",
      "Label neutral: 0.0431024432182312\n",
      "Label positive: 0.9506090879440308\n",
      "\n",
      "Sentiment of aspect 'clinton' is:\n",
      "Label negative: 0.007390960585325956\n",
      "Label neutral: 0.08220380544662476\n",
      "Label positive: 0.910405158996582\n",
      "\n",
      "Overall sentiment: neutral with score 0.4422141909599304\n",
      "\n",
      "Tweet: retweet for trump neverhillary \n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.008591235615313053\n",
      "Label neutral: 0.9845172762870789\n",
      "Label positive: 0.0068915304727852345\n",
      "\n",
      "Sentiment of aspect 'hillary' is:\n",
      "Label negative: 0.09125899523496628\n",
      "Label neutral: 0.9058268666267395\n",
      "Label positive: 0.0029141202103346586\n",
      "\n",
      "Aspect 'clinton' not found in the sentence.\n",
      "Overall sentiment: negative with score 0.3923370838165283\n",
      "\n",
      "Tweet: who will be the next president in usa? clinton or trump?\n",
      "\n",
      "predictions odds &amp; no deposit free bets &gt;… \n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.022141117602586746\n",
      "Label neutral: 0.9569631814956665\n",
      "Label positive: 0.020895687863230705\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Sentiment of aspect 'clinton' is:\n",
      "Label negative: 0.020189771428704262\n",
      "Label neutral: 0.9651577472686768\n",
      "Label positive: 0.014652504585683346\n",
      "\n",
      "Overall sentiment: neutral with score 0.8334972262382507\n",
      "\n",
      "Tweet: obama didn't do half the things he promised, why is trump any different? &amp; don't say republican congress bc republicans don't even like him\n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.8798985481262207\n",
      "Label neutral: 0.08735150098800659\n",
      "Label positive: 0.03274989500641823\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Aspect 'clinton' not found in the sentence.\n",
      "Overall sentiment: negative with score 0.8963462710380554\n",
      "\n",
      "Tweet: trump gets a republican congress \n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.012653008103370667\n",
      "Label neutral: 0.13721828162670135\n",
      "Label positive: 0.8501287698745728\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Aspect 'clinton' not found in the sentence.\n",
      "Overall sentiment: neutral with score 0.5319318175315857\n",
      "\n",
      "Tweet: trump was a democrat like 10 years ago. you'll be fine.\n",
      "Sentiment of aspect 'trump' is:\n",
      "Label negative: 0.5868232846260071\n",
      "Label neutral: 0.3987966477870941\n",
      "Label positive: 0.014380053617060184\n",
      "\n",
      "Aspect 'hillary' not found in the sentence.\n",
      "Aspect 'clinton' not found in the sentence.\n",
      "Overall sentiment: neutral with score 0.43853119015693665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define keywords\n",
    "trump_keywords = [\"trump\"]\n",
    "hillary_keywords = [\"hillary\", \"clinton\"]\n",
    "all_keywords = [\"trump\", \"hillary\", \"clinton\"]\n",
    "\n",
    "# Sample 10 tweets for Trump and Hillary\n",
    "trump_tweets_sample = trump_tweets.sample(10)  # Random 10 samples\n",
    "hillary_tweets_sample = hillary_tweets.sample(10)\n",
    "interesting_tweets_sample = interesting_tweets.sample(10)\n",
    "\n",
    "# Apply keyword-specific sentiment analysis\n",
    "# print(\"Trump tweets and sentiment\")\n",
    "# for _, tweet in trump_tweets_sample.iterrows():  # Use iterrows to loop over rows\n",
    "#     print(f\"Tweet: {tweet['cleaned_text']}\")\n",
    "#     sentiment_results_trump = analyze_aspects_sentiment(\n",
    "#         tweet['cleaned_text'], trump_keywords, absa_tokenizer, absa_model, sentiment_model\n",
    "#     )\n",
    "#     print()\n",
    "\n",
    "# print(\"Hillary tweets and sentiment\")\n",
    "# for _, tweet in hillary_tweets_sample.iterrows():  # Use iterrows to loop over rows\n",
    "#     print(f\"Tweet: {tweet['cleaned_text']}\")\n",
    "#     sentiment_results_hillary = analyze_aspects_sentiment(\n",
    "#         tweet['cleaned_text'], hillary_keywords, absa_tokenizer, absa_model, sentiment_model\n",
    "#     )\n",
    "#     print()\n",
    "\n",
    "# Apply keyword-specific sentiment analysis\n",
    "print(\"Overall tweets and sentiment\")\n",
    "for _, tweet in interesting_tweets_sample.iterrows():  # Use iterrows to loop over rows\n",
    "    print(f\"Tweet: {tweet['cleaned_text']}\")\n",
    "    sentiment_results_tweets = analyze_aspects_sentiment(\n",
    "        tweet['cleaned_text'], all_keywords, absa_tokenizer, absa_model, sentiment_model\n",
    "    )\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
