{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9ce3785-2e5b-4efe-b62a-d346771612f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import zipfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ee825bd-e33b-43d4-bc9b-0300ceecf116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download VADER's required data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f766831-7cab-41bb-9dc6-f6faa803c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product, it's amazing!\n",
      "Scores: {'neg': 0.0, 'neu': 0.266, 'pos': 0.734, 'compound': 0.8516}\n",
      "Text: This is terrible, I hate it.\n",
      "Scores: {'neg': 0.694, 'neu': 0.306, 'pos': 0.0, 'compound': -0.7783}\n",
      "Text: Meh, it was okay but not great.\n",
      "Scores: {'neg': 0.506, 'neu': 0.362, 'pos': 0.131, 'compound': -0.6299}\n"
     ]
    }
   ],
   "source": [
    "# Example sentences\n",
    "texts = [\n",
    "    \"I love this product, it's amazing!\",\n",
    "    \"This is terrible, I hate it.\",\n",
    "    \"Meh, it was okay but not great.\"\n",
    "]\n",
    "\n",
    "# Analyze each text\n",
    "for text in texts:\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17183d15-b748-4dae-a32e-b6eb69c25b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 397629 entries, 162840 to 92778\n",
      "Data columns (total 34 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           397629 non-null  object \n",
      " 1   created_at                     397629 non-null  object \n",
      " 2   geo                            2564 non-null    object \n",
      " 3   lang                           397629 non-null  object \n",
      " 4   place                          30832 non-null   object \n",
      " 5   coordinates                    2564 non-null    object \n",
      " 6   user.favourites_count          397629 non-null  int64  \n",
      " 7   user.statuses_count            397629 non-null  int64  \n",
      " 8   user.description               353403 non-null  object \n",
      " 9   user.location                  302677 non-null  object \n",
      " 10  user.id                        397629 non-null  int64  \n",
      " 11  user.created_at                397629 non-null  object \n",
      " 12  user.verified                  397629 non-null  bool   \n",
      " 13  user.following                 397629 non-null  bool   \n",
      " 14  user.url                       172193 non-null  object \n",
      " 15  user.listed_count              397629 non-null  int64  \n",
      " 16  user.followers_count           397629 non-null  int64  \n",
      " 17  user.default_profile_image     397629 non-null  bool   \n",
      " 18  user.utc_offset                273213 non-null  float64\n",
      " 19  user.friends_count             397629 non-null  int64  \n",
      " 20  user.default_profile           397629 non-null  bool   \n",
      " 21  user.name                      397614 non-null  object \n",
      " 22  user.lang                      397629 non-null  object \n",
      " 23  user.screen_name               397629 non-null  object \n",
      " 24  user.geo_enabled               397629 non-null  bool   \n",
      " 25  user.profile_background_color  397629 non-null  object \n",
      " 26  user.profile_image_url         397629 non-null  object \n",
      " 27  user.time_zone                 273213 non-null  object \n",
      " 28  id                             397629 non-null  int64  \n",
      " 29  favorite_count                 397629 non-null  int64  \n",
      " 30  retweeted                      397629 non-null  bool   \n",
      " 31  source                         397629 non-null  object \n",
      " 32  favorited                      397629 non-null  bool   \n",
      " 33  retweet_count                  397629 non-null  int64  \n",
      "dtypes: bool(7), float64(1), int64(9), object(17)\n",
      "memory usage: 87.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'election_day_tweets_data/election_day_tweets.csv'  # Replace with the actual file name\n",
    "elections_2016 = pd.read_csv(file_path)\n",
    "\n",
    "elections_2016.sort_values(by='created_at').info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "15114eae-79eb-4d76-849c-08f9c56921b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        # Remove special characters, numbers, and extra whitespace\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)        # Replace multiple spaces with a single space\n",
    "        text = text.strip()                     # Remove leading/trailing spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1f88837-83f0-4bae-97ae-93bfaacb5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Hillary Tweets:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['sentiment', 'compound_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Display example Hillary Tweets\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample Hillary Tweets:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhillary_tweets\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompound_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Show the first 5 tweets related to Hillary\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Display example Trump Tweets\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExample Trump Tweets:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\TNM108\\Project\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\TNM108\\Project\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\TNM108\\Project\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['sentiment', 'compound_score'] not in index\""
     ]
    }
   ],
   "source": [
    "elections_2016['text'] = elections_2016['text'].str.lower()  # Convert to lowercase\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "elections_2016['cleaned_text'] = elections_2016['text'].apply(clean_text)\n",
    "#print(elections_2016[['cleaned_text']].head())\n",
    "\n",
    "# Define specific words to search for\n",
    "specific_words = ['hillary', 'clinton']\n",
    "\n",
    "# Combine the words into a single regular expression pattern\n",
    "pattern = '|'.join(rf'\\b{word}\\b' for word in specific_words)  # Matches whole words only\n",
    "\n",
    "# Filter rows where the cleaned text contains any of the specific words\n",
    "hillary_tweets = elections_2016[elections_2016['cleaned_text'].str.contains(pattern, flags=re.IGNORECASE, na=False)]\n",
    "# Filter tweets related to Trump\n",
    "trump_tweets = elections_2016[elections_2016['cleaned_text'].str.contains('trump', case=False, na=False)]\n",
    "\n",
    "# Save the filtered results\n",
    "filtered_elections_2016.to_csv('filtered_words2.csv', index=False)\n",
    "\n",
    "# Display example Hillary Tweets\n",
    "print(\"Example Hillary Tweets:\")\n",
    "print(hillary_tweets[['cleaned_text']].head())  # Show the first 5 tweets related to Hillary\n",
    "\n",
    "# Display example Trump Tweets\n",
    "print(\"\\nExample Trump Tweets:\")\n",
    "print(trump_tweets[['cleaned_text']].head())  # Show the first 5 tweets related to Trump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48194e29-c814-4b54-a9db-b5027d026b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#elections_2016['text'] = elections_2016['text'].str.lower()\n",
    "\n",
    "#elections_2016['text'] = elections_2016['text'].astype(str)  # Convert 'text' column to string data type\n",
    "\n",
    "#elections_2016['tokens'] = elections_2016['text'].apply(nltk.word_tokenize)  # Tokenization\n",
    "\n",
    "#elections_2016 = elections_2016.head(100)  # This selects the first 100 rows\n",
    "\n",
    "\n",
    "# Remove stopwords\n",
    "#stopwords = nltk.corpus.stopwords.words('english')\n",
    "#elections_2016['tokens'] = elections_2016['tokens'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "#elections_2016['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0773af4-b800-4320-9b77-87703b016dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze sentiment for each row\n",
    "elections_2016['sentiment_scores'] = elections_2016['cleaned_text'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "elections_2016['compound_score'] = elections_2016['sentiment_scores'].apply(lambda x: x['compound'])\n",
    "elections_2016['sentiment'] = elections_2016['compound_score'].apply(\n",
    "    lambda x: \"Positive\" if x > 0.05 else \"Negative\" if x < -0.05 else \"Neutral\"\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "elections_2016.to_csv('election_sentiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba573e6-5769-44f3-bc08-c19882b82ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Positive Tweets\n",
    "positive_tweets = hillary_tweets[hillary_tweets['sentiment'] == 'Positive']\n",
    "print(\"Example Positive Hillary Tweets:\")\n",
    "print(positive_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 positive tweets\n",
    "\n",
    "# Example Negative Tweets\n",
    "negative_tweets = hillary_tweets[hillary_tweets['sentiment'] == 'Negative']\n",
    "print(\"\\nExample Hillary Negative Tweets:\")\n",
    "print(negative_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 negative tweets\n",
    "\n",
    "# Example Neutral Tweets\n",
    "neutral_tweets = hillary_tweets[hillary_tweets['sentiment'] == 'Neutral']\n",
    "print(\"\\nExample Hillary Neutral Tweets:\")\n",
    "print(neutral_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 neutral tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e4f1f-961d-4375-8416-afcffaed73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Positive Tweets\n",
    "positive_tweets = trump_tweets[trump_tweets['sentiment'] == 'Positive']\n",
    "print(\"Example Positive Trump Tweets:\")\n",
    "print(positive_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 positive tweets\n",
    "\n",
    "# Example Negative Tweets\n",
    "negative_tweets = trump_tweets[trump_tweets['sentiment'] == 'Negative']\n",
    "print(\"\\nExample Trump Negative Tweets:\")\n",
    "print(negative_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 negative tweets\n",
    "\n",
    "# Example Neutral Tweets\n",
    "neutral_tweets = trump_tweets[trump_tweets['sentiment'] == 'Neutral']\n",
    "print(\"\\nExample Trump Neutral Tweets:\")\n",
    "print(neutral_tweets[['cleaned_text', 'sentiment', 'compound_score']].head())  # Show the first 5 neutral tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab94a5-d1ee-458a-aaef-06f9b716ac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
